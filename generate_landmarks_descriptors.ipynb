{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 0 - Imports and defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from pyFM.mesh import TriMesh\n",
    "from pyFM.functional import FunctionalMapping\n",
    "\n",
    "import meshplot as mp\n",
    "\n",
    "import os\n",
    "\n",
    "def plot_mesh(myMesh,cmap=None):\n",
    "    mp.plot(myMesh.vertlist, myMesh.facelist,c=cmap)\n",
    "    \n",
    "def double_plot(myMesh1,myMesh2,cmap1=None,cmap2=None):\n",
    "    d = mp.subplot(myMesh1.vertlist, myMesh1.facelist, c=cmap1, s=[2, 2, 0])\n",
    "    mp.subplot(myMesh2.vertlist, myMesh2.facelist, c=cmap2, s=[2, 2, 1], data=d)\n",
    "\n",
    "def visu(vertices):\n",
    "    min_coord,max_coord = np.min(vertices,axis=0,keepdims=True),np.max(vertices,axis=0,keepdims=True)\n",
    "    cmap = (vertices-min_coord)/(max_coord-min_coord)\n",
    "    return cmap\n",
    "\n",
    "def export_results(p2p, name):\n",
    "    # open file in write mode\n",
    "    with open(r'data_out/'+ name + '.txt', 'w') as f_export_init:\n",
    "        for item in p2p:\n",
    "            # write each item on a new line\n",
    "            f_export_init.write(\"%s\\n\" % item)\n",
    "        print('Exported' + name + 'point to point mapping \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input folder name\n",
    "inputFolder = 'PAIR_TEST'\n",
    "# Concatenate folder name with the path\n",
    "inputPath = '../../data/' + inputFolder + '/'\n",
    "mesh1 = TriMesh(inputPath + 'target.off', area_normalize=True, center=True)\n",
    "mesh2 = TriMesh(inputPath + 'source.off', area_normalize=True, center=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Visualization of eigen functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default does not use the intrinsic delaunay Laplacian\n",
    "mesh2.process(k=100, intrinsic=False, verbose=True);\n",
    "\n",
    "# set up a figure twice as wide as it is tall\n",
    "i = 0\n",
    "d = mp.subplot(mesh2.vertlist, mesh1.facelist, c=mesh2.eigenvectors[:,i], s=[1, 10, 0])\n",
    "for i in range(1,10):\n",
    "    d = mp.subplot(mesh2.vertlist, mesh1.facelist, c=mesh2.eigenvectors[:,i], s=[1, 10, i], data=d)\n",
    "\n",
    "#d.save(\"myplottest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Computing the landmarks based descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying data with correspondences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mesh 1 : {mesh1.n_vertices:4d} vertices, {mesh1.n_faces:5d} faces\\n'\n",
    "      f'Mesh 2 : {mesh2.n_vertices:4d} vertices, {mesh2.n_faces:5d} faces')\n",
    "\n",
    "loadLandmark = True\n",
    "if loadLandmark:\n",
    "    landmarks = np.loadtxt(inputPath +'landmarks.txt',dtype=int)[:10]  # loading N landmarks\n",
    "    display(landmarks)\n",
    "\n",
    "    landmarks_mesh1 = TriMesh(mesh1.vertlist[landmarks[:,0]])\n",
    "    landmarks_mesh2 = TriMesh(mesh2.vertlist[landmarks[:,1]])\n",
    "\n",
    "    print('Retrieved matching faces from CT & RGBD pointclouds')\n",
    "    \n",
    "else:\n",
    "     landmarks = []\n",
    "\n",
    "#d = mp.subplot(mesh1.vertlist, mesh1.facelist, None, s=[2, 2, 0])\n",
    "\n",
    "p1 = mp.plot(mesh1.vertlist, mesh1.facelist, None)\n",
    "p2 = mp.plot(mesh2.vertlist, mesh2.facelist, None)\n",
    "\n",
    "if loadLandmark:\n",
    "    color = c=np.random.rand(*landmarks_mesh1.vertlist.shape)\n",
    "    p1.add_points(landmarks_mesh1.vertlist, c = color, shading={\"point_size\": 0.3})\n",
    "    p2.add_points(landmarks_mesh2.vertlist, c = color, shading={\"point_size\": 0.3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing descriptors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True\n",
    "\n",
    "model = FunctionalMapping(mesh1,mesh2)\n",
    "\n",
    "n_ev = (25,25)  # Number of eigenvalues on source and Target\n",
    "descr_type = 'HKS'\n",
    "model.k1, model.k2 = n_ev\n",
    "\n",
    "k_process = 200\n",
    "\n",
    "use_lm = landmarks is not None and len(landmarks) > 0\n",
    "\n",
    "# Compute the Laplacian spectrum\n",
    "if verbose:\n",
    "    print('\\nComputing Laplacian spectrum')\n",
    "model.mesh1.process(max(model.k1, k_process), verbose=verbose)\n",
    "model.mesh2.process(max(model.k2, k_process), verbose=verbose)\n",
    "\n",
    "if verbose:\n",
    "    print('\\nComputing descriptors')\n",
    "\n",
    "# Extract landmarks indices\n",
    "if use_lm:\n",
    "    lmks1, lmks2 = model._get_lmks(landmarks, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyFM.signatures as sg\n",
    "n_descr = 5\n",
    "subsample_step = 5\n",
    "\n",
    "# Compute descriptors\n",
    "if descr_type == 'HKS':\n",
    "    if use_lm:\n",
    "        lm_descr1 = sg.mesh_HKS(model.mesh1, n_descr,landmarks=lmks1, k=model.k1)  # (N1, p*n_descr)\n",
    "        lm_descr2 = sg.mesh_HKS(model.mesh2, n_descr, landmarks=lmks2, k=model.k2)  # (N2, p*n_descr)\n",
    "\n",
    "elif descr_type == 'WKS':\n",
    "    if use_lm:\n",
    "        lm_descr1 = sg.mesh_WKS(model.mesh1, n_descr, landmarks=lmks1, k=model.k1)  # (N1, p*n_descr)\n",
    "        lm_descr2 = sg.mesh_WKS(model.mesh2, n_descr, landmarks=lmks2, k=model.k2)  # (N2, p*n_descr)\n",
    "        \n",
    "else:\n",
    "    raise ValueError(f'Descriptor type \"{descr_type}\" not implemented')\n",
    "\n",
    "## Subsample descriptors\n",
    "#lm_descr1 = lm_descr1[:, np.arange(0, lm_descr1.shape[1], subsample_step)]\n",
    "#lm_descr2 = lm_descr2[:, np.arange(0, lm_descr2.shape[1], subsample_step)]\n",
    "\n",
    "# Normalize descriptors\n",
    "#if verbose:\n",
    "#    print('\\tNormalizing descriptors')\n",
    "#\n",
    "#no1 = np.sqrt(model.mesh1.l2_sqnorm(lm_descr1))  \n",
    "#no2 = np.sqrt(model.mesh2.l2_sqnorm(lm_descr2)) \n",
    "#\n",
    "#model.descr1 /= no1[None, :]\n",
    "#model.descr2 /= no2[None, :]\n",
    "#\n",
    "#if verbose:\n",
    "#    n_lmks = np.asarray(landmarks).shape[0] if use_lm else 0\n",
    "#    print(f'\\n\\t{model.descr1.shape[1]} out of {n_descr*(1+n_lmks)} possible descriptors kept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name_1 = 'lm_descr1'\n",
    "export_name_2 = 'lm_descr2'\n",
    "\n",
    "# Concatenate the descriptor type to the export name\n",
    "if descr_type == 'HKS':\n",
    "\n",
    "    export_name_1 = export_name_1 + '_HKS'\n",
    "    export_name_2 = export_name_2 + '_HKS'\n",
    "elif descr_type == 'WKS':\n",
    "    export_name_1 = export_name_1 + '_WKS'\n",
    "    export_name_2 = export_name_2 + '_WKS'\n",
    "\n",
    "# Export the descriptors to a txt file\n",
    "export_name_1 = export_name_1 + '.txt'\n",
    "export_name_2 = export_name_2 + '.txt'\n",
    "\n",
    "# Display export name\n",
    "print(export_name_1)\n",
    "print(export_name_2)\n",
    "\n",
    "np.savetxt(export_name_1 , lm_descr1, delimiter=',')\n",
    "np.savetxt(export_name_2 , lm_descr2, delimiter=',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_params = {\n",
    "    'n_ev': (25,25),  # Number of eigenvalues on source and Target\n",
    "    'landmarks': landmarks,  # loading 5 landmarks\n",
    "    'subsample_step': 5,  # In order not to use too many descriptors\n",
    "    'descr_type': 'HKS',  # WKS or HKS\n",
    "}\n",
    "\n",
    "\n",
    "model = FunctionalMapping(mesh1,mesh2)\n",
    "model.preprocess(**process_params,verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
    "$\\newcommand{\\Ss}{\\mathcal{S}}$\n",
    "$\\newcommand{\\uargmin}[1]{\\underset{#1}{\\text{argmin}}\\;}$\n",
    "$\\newcommand{\\uargmax}[1]{\\underset{#1}{\\text{argmax}}\\;}$\n",
    "$\\def\\*#1{\\mathbf{#1}}$\n",
    "\n",
    "In pyFM, we always consider functional maps $\\*C:\\Ss_1\\to\\Ss_2$ and pointwise maps $T:\\Ss_2\\to\\Ss_1$ going in opposite directions, with $\\*C$ always going from shape 1 to shape 2 !\n",
    "\n",
    "Optimization problem is\n",
    "\\begin{equation}\n",
    "\\uargmin{\\*C\\in\\RR^{k_2\\times k_1}} w_{descr}\\|\\*C\\*A - \\*B\\|^2 + w_{lap}\\|\\*C\\Delta_1 - \\Delta_2\\*C\\|^2 + w_{\\text{d- comm}}\\sum_i \\|\\*C\\Gamma_1^i - \\Gamma_2^i\\*C\\|^2 + w_{\\text{orient}}\\sum_i \\|\\*C\\Lambda_1^i - \\Lambda_2^i\\*C\\|^2\n",
    "\\end{equation}\n",
    "\n",
    "with $\\Gamma_1^i$ and $\\Gamma_2^i$ [multipliative operators](http://www.lix.polytechnique.fr/~maks/papers/fundescEG17.pdf) associated to the $i$-th descriptors, $\\Lambda_1^i$ and $\\Lambda_2^i$ [orientation preserving operators](https://arxiv.org/abs/1806.04455) associated to the $i$-th descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\n",
    "    'w_descr': 1e0, #scaling for the descriptor preservation term\n",
    "    'w_lap': 1e-2, #scaling of the laplacian commutativity term\n",
    "    'w_dcomm': 1e-1, #scaling of the multiplicative operator commutativity\n",
    "    'w_orient': 0, #scaling of the orientation preservation term\n",
    "    #'orient_reversing':True, #Whether to use the orientation reversing term instead of the orientation preservation one\n",
    "    #'optinit':'zeros' #Initialization\n",
    "\n",
    "}\n",
    "\n",
    "model.fit(**fit_params, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the associated point to point map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p2p_21 = model.get_p2p(n_jobs=1)\n",
    "cmap1 = visu(mesh1.vertlist); cmap2 = cmap1[p2p_21]\n",
    "double_plot(mesh1,mesh2,cmap1,cmap2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d4fdb5c5338a8fa7b742ce98cb975129d6aa57d42a9958c3fdc924baafbc05e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
